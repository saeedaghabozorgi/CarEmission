{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression with Spark\n",
    "What is Apache Spark [http://spark.apache.org/](http://spark.apache.org/)? Learn more about Apache Spark through [**Big Data University**](http://bigdatauniversity.com):\n",
    "\n",
    "- [**Spark Fundamentals I**](http://bigdatauniversity.com/bdu-wp/bdu-course/spark-fundamentals/)\n",
    "    - Describe what Spark is all about know why you would want to use Spark \n",
    "    - Use Resilient Distributed Datasets operations \n",
    "    - Use Scala, Java, or Python to create and run a Spark application \n",
    "    - Create applications using Spark SQL, MLlib, Spark Streaming, and GraphX \n",
    "    - Configure, monitor and tune Spark  \n",
    "    \n",
    "- [**Spark Fundamentals II**](http://bigdatauniversity.com/bdu-wp/bdu-course/spark-fundamentals-ii/) \n",
    "    - Apache Spark architecture overview \n",
    "    - Understanding input, partitioning, and parallelization \n",
    "    - Optimizations for efficiently operating on and joining multiple datasets \n",
    "    - Understanding how Spark instructions are translated into jobs and what causes multiple stages within a job \n",
    "    - Efficiently using Sparkâ€™s memory caching for iterative processing \n",
    "    - Developing, testing, and debugging Spark applications using SBT, Eclipse   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS, LogisticRegressionModel\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.stat import Statistics\n",
    "import pandas as pd\n",
    "import pylab as pl\n",
    "import numpy as np\n",
    "import matplotlib \n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading Data\n",
    "To download the data, we will use !wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget -O /resources/FuelConsumption.csv https://ibm.box.com/shared/static/ez95yurarnp0q31l9jl1ma51mh6qtxj2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##Understanding the Data\n",
    "\n",
    "###`FuelConsumption.csv`:\n",
    "We have downloaded a fuel consumption dataset, **`FuelConsumption.csv`**, which contains model-specific fuel consumption ratings and estimated carbon dioxide emissions for new light-duty vehicles for retail sale in Canada. [Dataset source](http://open.canada.ca/data/en/dataset/98f1a129-f628-4ce4-b24d-6f16bf24dd64)\n",
    "\n",
    "\n",
    "- **MAKE**\n",
    "- **MODEL**\n",
    "- **VEHICLE CLASS**\n",
    "- **ENGINE SIZE**\n",
    "- **CYLINDERS**\n",
    "- **TRANSMISSION**\n",
    "- **FUEL**\n",
    "- **FUEL CONSUMPTION in CITY(L/100 km)** \n",
    "- **FUEL CONSUMPTION in HWY (L/100 km)** \n",
    "- **FUEL CONSUMPTION COMB (L/100 km)** \n",
    "- **FUEL CONSUMPTION COMB (mpg)** \n",
    "- **CO2 EMISSIONS (g/km)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rawRDD = sc.textFile('/resources/FuelConsumption.csv') \n",
    "header = rawRDD.first() #extract header\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "carRDD = rawRDD.filter(lambda x:x !=header).map(lambda line: line.split(\",\"))\n",
    "carRDD.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data exploration\n",
    "We use **column summary statistics** for RDD[Vector] through the function **colStats** available in **Statistics**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sd=carRDD.map(lambda x: [float(x[4]),float(x[5]),float(x[12])])\n",
    "summary =Statistics.colStats(sd)\n",
    "print(summary.mean())\n",
    "print(summary.variance())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Labeling dataset\n",
    "We make a **labeled point** data type for regression. It includes a feature vector and a label (which is a floating-point value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load and parse the data\n",
    "def parseFeature(record):\n",
    "    features = [record[4],record[5]]  # ENGINESIZE,CYLINDERS\n",
    "    label =  [0,1][float(record[12])>256.22]  # 0:low, 1:High\n",
    "    return LabeledPoint(label,features)\n",
    "lblRDD=carRDD.map(parseFeature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lblRDD.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing: Spliting dataset into train and test dtasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lblRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainRDD,testRDD=lblRDD.randomSplit([0.7,0.3])\n",
    "trainRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testRDD.count()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = LogisticRegressionWithLBFGS.train(trainRDD)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make prediction.\n",
    "test_case=[5.7, 8.0]\n",
    "prediction = model.predict(test_case)\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make prediction.\n",
    "test_case=[4, 6.0]\n",
    "prediction = model.predict(test_case)\n",
    "print prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluating the model on training data\n",
    "labelsAndPreds = testRDD.map(lambda p: (p.label, model.predict(p.features)))\n",
    "labelsAndPreds.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testErr = labelsAndPreds.filter(lambda (v, p): v != p).count() / float(trainRDD.count())\n",
    "print(\"Test Error = \" + str(testErr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "model.save(sc, \"myModelPath2\")\n",
    "sameModel = LogisticRegressionModel.load(sc, \"myModelPath2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contact the Notebook Authors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), Data Scientist, IBM.** saeed[at]ca.ibm.com  \n",
    "1. **[Polong Lin](https://ca.linkedin.com/in/polonglin), Data Scientist, IBM.** polong[at]ca.ibm.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
